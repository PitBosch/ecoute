# Ecoute - Riconoscimento Vocale Multilingue

Ecoute Ã¨ un'applicazione di riconoscimento vocale in tempo reale che supporta multiple lingue, inclusa l'italiano. L'applicazione puÃ² trascrivere sia l'audio dal microfono che l'audio riprodotto dagli altoparlanti del sistema.

## Caratteristiche

- **Supporto Multilingue**: Italiano, Inglese, Spagnolo, Francese, Tedesco, Portoghese, Hindi, Olandese
- **Riconoscimento in Tempo Reale**: Trascrizione simultanea di microfono e altoparlanti
- **Interfaccia Grafica Moderna**: UI intuitiva con PyQt6 e CustomTkinter
- **Modelli Avanzati**: 
  - ğŸš€ **Voxtral-Mini-3B-2507** (Nuovo!) - Comprensione audio avanzata
  - Faster Whisper locali
  - OpenVINO Whisper ottimizzato 
  - OpenAI Whisper API
  - Ollama Whisper
- **Cambio Lingua Dinamico**: PossibilitÃ  di cambiare lingua durante l'uso
- **Database Locale**: Salvataggio automatico delle trascrizioni

## Installazione

1. **Clona il repository**:
   ```bash
   git clone <repository-url>
   cd ecoute
   ```

2. **Installa le dipendenze**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Installa FFmpeg** (richiesto per l'elaborazione audio):
   - **Windows**: Scarica da [ffmpeg.org](https://ffmpeg.org/download.html) e aggiungi al PATH
   - **macOS**: `brew install ffmpeg`
   - **Linux**: `sudo apt install ffmpeg`

## Utilizzo

### ğŸš€ Con Voxtral-Mini-3B (Nuovo!)
```bash
# Setup automatico
python setup_voxtral.py

# Interfaccia moderna (consigliata)
python run_modern.py --voxtral

# Interfaccia classica
python main.py --voxtral
```
*Nota: Richiede GPU con 10GB+ VRAM per prestazioni ottimali*

### Avvio Base (FasterWhisper)
```bash
# Interfaccia moderna
python run_modern.py

# Interfaccia classica
python main.py
```

### Con OpenVINO (Ottimizzato CPU)
```bash
python run_modern.py --openvino
```

### Con Ollama
```bash
python main.py --ollama
```
*Nota: Richiede Ollama installato da https://ollama.ai*

### Con OpenAI API
```bash
python run_modern.py --api
```
*Nota: Richiede una chiave API OpenAI configurata nell'ambiente*

### Controlli dell'Interfaccia

- **Menu Lingua**: Seleziona la lingua per il riconoscimento vocale
- **Area Trascrizione**: Visualizza le trascrizioni in tempo reale
- **Pulsante "Cancella Trascrizione"**: Pulisce la cronologia delle trascrizioni

## Lingue Supportate

### Voxtral-Mini-3B (Supporto Nativo)
- ğŸ‡®ğŸ‡¹ **Italiano** (it) - Eccellente
- ğŸ‡ºğŸ‡¸ **Inglese** (en) - Eccellente  
- ğŸ‡ªğŸ‡¸ **Spagnolo** (es) - Eccellente
- ğŸ‡«ğŸ‡· **Francese** (fr) - Eccellente
- ğŸ‡©ğŸ‡ª **Tedesco** (de) - Eccellente
- ğŸ‡µğŸ‡¹ **Portoghese** (pt) - Eccellente
- ğŸ‡®ğŸ‡³ **Hindi** (hi) - Eccellente
- ğŸ‡³ğŸ‡± **Olandese** (nl) - Eccellente

### Altri Modelli (100+ lingue)
Tutti gli altri modelli supportano 100+ lingue tramite Whisper

## Modelli di Trascrizione

### 1. **Ollama Whisper** â­ **RACCOMANDATO**
- **VelocitÃ **: Molto veloce
- **Accuratezza**: Alta
- **Costo**: Gratuito
- **Requisiti**: Ollama installato
- **Comando**: `python main.py --ollama`

### 2. **Faster Whisper** (Default)
- **VelocitÃ **: Media
- **Accuratezza**: Buona
- **Costo**: Gratuito
- **Requisiti**: GPU opzionale
- **Comando**: `python main.py`

### 3. **OpenAI Whisper API**
- **VelocitÃ **: Alta
- **Accuratezza**: Molto alta
- **Costo**: $0.006/minuto
- **Requisiti**: Chiave API
- **Comando**: `python main.py --api`

## Configurazione

### Variabili d'Ambiente

Per utilizzare l'API OpenAI:
```bash
export OPENAI_API_KEY="your-api-key-here"
```

### Parametri Audio

I parametri di registrazione possono essere modificati in `AudioRecorder.py`:
- `RECORD_TIMEOUT`: Timeout per la registrazione (default: 3 secondi)
- `ENERGY_THRESHOLD`: Soglia di energia per il rilevamento vocale
- `DYNAMIC_ENERGY_THRESHOLD`: Soglia dinamica abilitata/disabilitata

## Struttura del Progetto

```
ecoute/
â”œâ”€â”€ main.py                 # Punto di ingresso principale
â”œâ”€â”€ AudioRecorder.py        # Gestione registrazione audio
â”œâ”€â”€ AudioTranscriber.py     # Trascrizione audio
â”œâ”€â”€ TranscriberModels.py    # Modelli di riconoscimento vocale
â”œâ”€â”€ custom_speech_recognition/  # Libreria personalizzata
â””â”€â”€ requirements.txt        # Dipendenze Python
```

## Risoluzione Problemi

### Errore "pyaudiowpatch could not be resolved"
Assicurati di aver installato PyAudioWPatch:
```bash
pip install PyAudioWPatch
```

### Errore FFmpeg
Verifica che FFmpeg sia installato e accessibile dal PATH:
```bash
ffmpeg -version
```

### Problemi di Performance
- Per migliori performance, utilizza una GPU CUDA
- Il modello "base" Ã¨ piÃ¹ accurato ma piÃ¹ lento del modello "tiny"

## ğŸ“š Documentazione Aggiuntiva

- ğŸ™ï¸ **[Guida Voxtral](README_VOXTRAL.md)** - Setup e utilizzo del modello Voxtral-Mini-3B-2507
- ğŸ”§ **[Guida OpenVINO](README_OPENVINO.md)** - Ottimizzazione CPU con Intel OpenVINO
- ğŸ¯ **[Interfaccia Moderna](README_MODERN.md)** - Guida all'interfaccia PyQt6

## Licenza

Questo progetto Ã¨ rilasciato sotto licenza MIT. Vedi il file `LICENSE` per i dettagli.

## Contributi

I contributi sono benvenuti! Per favore:
1. Fai un fork del progetto
2. Crea un branch per la tua feature
3. Committa le modifiche
4. Apri una Pull Request

## Supporto

Per problemi o domande, apri una issue su GitHub.
